Training started at 2025-12-23 09:50:41
============================================================
Command: C:\1_GitHome\Local-LLM-Server\LLM\.venv\Scripts\python.exe -u train_basic.py --model-name C:\1_GitHome\Local-LLM-Server\LLM\models\nvidia_Llama-3.1-Nemotron-Nano-8B-v1 --data-path train_data.jsonl --output-dir ./models_trained/Nemotron_23_20251223_095041 --epochs 1 --batch-size 1 --lora-r 8 --lora-alpha 16 --lora-dropout 0.05 --grad-accum 8 --max-seq-length 2048
Working directory: C:\1_GitHome\Local-LLM-Server\LLM
Python executable: C:\1_GitHome\Local-LLM-Server\LLM\.venv\Scripts\python.exe
Finetune script: C:\1_GitHome\Local-LLM-Server\LLM\train_basic.py
Dataset: train_data.jsonl
Model: C:\1_GitHome\Local-LLM-Server\LLM\models\nvidia_Llama-3.1-Nemotron-Nano-8B-v1
Epochs: 1
Attempting to start subprocess...
Process started with PID: 9028
Process is running, starting output reader...
C:\1_GitHome\Local-LLM-Server\LLM\.venv\Lib\site-packages\transformers\utils\hub.py:110: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
⏳ Waiting for output from training process...
Configuration:
  Model: C:\1_GitHome\Local-LLM-Server\LLM\models\nvidia_Llama-3.1-Nemotron-Nano-8B-v1
  Dataset: train_data.jsonl
  Output: ./models_trained/Nemotron_23_20251223_095041
  Epochs: 1
  Batch Size: 1
  LoRA R: 8
  LoRA Alpha: 16
  LoRA Dropout: 0.05
  Gradient Accumulation: 8
  Max Seq Length: 2048
Loading model...
`torch_dtype` is deprecated! Use `dtype` instead!
The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:09,  3.28s/it]
Loading checkpoint shards:  50%|█████     | 2/4 [00:06<00:06,  3.06s/it]
Loading checkpoint shards:  75%|███████▌  | 3/4 [00:09<00:03,  3.11s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:10<00:00,  2.21s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:10<00:00,  2.54s/it]
Preparing model for training...
Adding LoRA adapters...
Loading dataset...
Generating train split: 0 examples [00:00, ? examples/s]
Generating train split: 3000 examples [00:00, 157158.71 examples/s]
Map:   0%|          | 0/3000 [00:00<?, ? examples/s]
Map: 100%|██████████| 3000/3000 [00:00<00:00, 75876.09 examples/s]
Map:   0%|          | 0/3000 [00:00<?, ? examples/s]
Map:  33%|███▎      | 1000/3000 [00:00<00:01, 1723.53 examples/s]
Map:  67%|██████▋   | 2000/3000 [00:01<00:00, 1687.93 examples/s]
Map: 100%|██████████| 3000/3000 [00:01<00:00, 1724.28 examples/s]
Map: 100%|██████████| 3000/3000 [00:01<00:00, 1685.11 examples/s]
Training...
  0%|          | 0/375 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
C:\1_GitHome\Local-LLM-Server\LLM\.venv\Lib\site-packages\torch\_dynamo\eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  return fn(*args, **kwargs)
⏳ Waiting for output from training process...
⚠️ No output for 60s. Model may be saving (this is normal at the end)...
⚠️ No output for 60s. Model may be saving (this is normal at the end)...
⚠️ No output for 60s. Model may be saving (this is normal at the end)...
⚠️ No output for 60s. Model may be saving (this is normal at the end)...
⚠️ No output for 60s. Model may be saving (this is normal at the end)...
⚠️ No output for 60s. Model may be saving (this is normal at the end)...
⚠️ No output for 60s. Model may be saving (this is normal at the end)...
⚠️ No output for 60s. Model may be saving (this is normal at the end)...
⚠️ No output for 60s. Model may be saving (this is normal at the end)...
⚠️ No output for 60s. Model may be saving (this is normal at the end)...
⚠️ No output for 60s. Model may be saving (this is normal at the end)...
⚠️ No output for 60s. Model may be saving (this is normal at the end)...
⚠️ No output for 60s. Model may be saving (this is normal at the end)...
⚠️ No output for 60s. Model may be saving (this is normal at the end)...
⚠️ No output for 60s. Model may be saving (this is normal at the end)...
⚠️ No output for 60s. Model may be saving (this is normal at the end)...
⚠️ No output for 60s. Model may be saving (this is normal at the end)...
⚠️ No output for 60s. Model may be saving (this is normal at the end)...
⚠️ No output for 60s. Model may be saving (this is normal at the end)...
⚠️ No output for 60s. Model may be saving (this is normal at the end)...
⚠️ No output for 60s. Model may be saving (this is normal at the end)...
⚠️ No output for 60s. Model may be saving (this is normal at the end)...
⚠️ No output for 60s. Model may be saving (this is normal at the end)...
⚠️ No output for 60s. Model may be saving (this is normal at the end)...
⚠️ No output for 60s. Model may be saving (this is normal at the end)...
⚠️ No output for 60s. Model may be saving (this is normal at the end)...
⚠️ No output for 60s. Model may be saving (this is normal at the end)...
⚠️ No output for 60s. Model may be saving (this is normal at the end)...
⚠️ No output for 60s. Model may be saving (this is normal at the end)...
⚠️ No output for 60s. Model may be saving (this is normal at the end)...
⚠️ No output for 60s. Model may be saving (this is normal at the end)...
⚠️ No output for 60s. Model may be saving (this is normal at the end)...
⚠️ No output for 60s. Model may be saving (this is normal at the end)...
⚠️ No output for 60s. Model may be saving (this is normal at the end)...
⚠️ No output for 60s. Model may be saving (this is normal at the end)...
⚠️ No output for 60s. Model may be saving (this is normal at the end)...
⚠️ No output for 60s. Model may be saving (this is normal at the end)...
⚠️ No output for 60s. Model may be saving (this is normal at the end)...
⚠️ No output for 60s. Model may be saving (this is normal at the end)...
⚠️ No output for 60s. Model may be saving (this is normal at the end)...
⚠️ No output for 60s. Model may be saving (this is normal at the end)...
⚠️ No output for 60s. Model may be saving (this is normal at the end)...
⚠️ No output for 60s. Model may be saving (this is normal at the end)...
⚠️ No output for 60s. Model may be saving (this is normal at the end)...
⚠️ No output for 60s. Model may be saving (this is normal at the end)...
⚠️ No output for 60s. Model may be saving (this is normal at the end)...
⚠️ No output for 60s. Model may be saving (this is normal at the end)...
⚠️ No output for 60s. Model may be saving (this is normal at the end)...
⚠️ No output for 60s. Model may be saving (this is normal at the end)...
⚠️ No output for 60s. Model may be saving (this is normal at the end)...
⚠️ No output for 60s. Model may be saving (this is normal at the end)...
⚠️ No output for 60s. Model may be saving (this is normal at the end)...
⚠️ No output for 60s. Model may be saving (this is normal at the end)...
⚠️ No output for 60s. Model may be saving (this is normal at the end)...
